import os
import sys
import socket
import subprocess
import time
import tempfile
import json
import dateutil.parser
import urllib.request
from pathlib import Path

import certifi
from packaging.requirements import Requirement
from packaging.utils import (
    canonicalize_name,
)


class Proxy:
    """
    Wrapper for mitmproxy.org

    We start an instance of mitmproxy to intercept requests by pip
    to ensure that pip doesn't see files which were published after
    the pypiSnapshotDate given to our script.
    It's generic enough that it should work with python mirrors
    besides pypi.org as well, but URLs for actual distribution files
    should not be intercepted for performance reasons and we
    currently just ignore files.pythonhosted.org by default.
    """

    def __init__(self, executable, args, env):
        self.env = env
        self.port = self.find_free_port()

        self.proc = subprocess.Popen(
            [
                executable,
                "--listen-port",
                str(self.port),
                "--anticache",
                *args,
            ],
            stdout=sys.stderr,
            stderr=sys.stderr,
            env=env,
        )
        self.wait("http://pypi.org", 10)
        self.cafile = self.generate_ca_bundle(".ca-cert.pem")

    def find_free_port(self):
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.bind(("", 0))
        port = sock.getsockname()[1]
        sock.close()
        return port

    def wait(self, test_url, timeout):
        """
        Wait for a bit until a given url is reachable via the proxy,
        as the latter starts asynchronous.
        """
        timeout = time.time() + timeout
        req = urllib.request.Request(test_url)
        req.set_proxy(f"127.0.0.1:{self.port}", "http")

        while time.time() < timeout:
            try:
                res = urllib.request.urlopen(req, None, 5)
                if res.status < 400:
                    break
            except urllib.error.URLError:
                pass
            finally:
                time.sleep(1)

    def generate_ca_bundle(self, path):
        """
        Because we only proxy *some* calls, but ignore i.e.
        files.pythonhosted.org we need to combine upstream ca certificates
        and the one generated by mitm proxy.
        """
        home = Path(self.env["HOME"])
        path = home / path
        with open(home / ".mitmproxy/mitmproxy-ca-cert.pem", "r") as f:
            mitmproxy_cacert = f.read()
        with open(certifi.where(), "r") as f:
            certifi_cacert = f.read()
        with open(path, "w") as f:
            f.write(mitmproxy_cacert)
            f.write("\n")
            f.write(certifi_cacert)
        return path

    def kill(self):
        self.proc.kill()


def call_nix(*args, check=True):
    return subprocess.run(
        ["nix", "--experimental-features", "nix-command flakes", *args],
        check=check,
        text=True,
        stdout=subprocess.PIPE,
        stderr=sys.stderr if check else subprocess.PIPE,
    )


def lock_info_from_fod(store_path, drv_path):
    # attrs are keyed by derivation path, which we don't know,
    # but there should be only one in our case.
    drv_json = list(json.loads(drv_path).values())[0]

    drv_out = drv_json.get("outputs", {}).get("out", {})
    assert str(store_path) == drv_out.get("path")
    assert "r:sha256" == drv_out.get("hashAlgo")
    url = drv_json.get("env", {}).get("urls")  # TODO multiple? commas?
    sha256 = drv_out.get("hash")
    if not (url and sha256):
        print(
            f"fatal: requirement '{store_path}' does not seem to be a FOD.\n",
            f"No URL ({url}) or hash ({sha256}) found.",
            file=sys.stderr,
        )
        sys.exit(1)
    return url, sha256


def lock_info_from_flake(store_path, full_path):
    flake_src = call_nix("eval", "--raw", ".#src")
    if flake_src and flake_src.stdout.strip() == str(full_path):
        url = str(full_path.relative_to(store_path))
        return url, None
    else:
        print(
            f"fatal: requirement '{full_path}' seems to refer to a flake which isn't ours.\n",  # noqa: E501
            "...or something else that is not yet supported, please open an issue.",  # noqa: E501
            file=sys.stderr,
        )
        sys.exit(1)


def lock_info_from_store_path(full_path):
    if not Path("/nix/store") in full_path.parents:
        print(
            f"fatal: requirement '{full_path}' refers to something outside /nix/store",  # noqa: E501
            file=sys.stderr,
        )
        sys.exit(1)

    # get just the "top-level" store path /nix/store/$hash-name/
    store_path = Path("/").joinpath(*full_path.parts[:4])
    # use nix to print the derivation of our out_path in json
    show_derivation = call_nix(
        "show-derivation", "--derivation", store_path, check=False
    )  # noqa: E501

    # Assume it's a FOD and get its url and sha256
    if show_derivation.returncode == 0:
        return lock_info_from_fod(store_path, show_derivation.stdout)
    # See whether it's a flake, and if so write the relative path into the lock
    # file.
    else:
        return lock_info_from_flake(store_path, full_path)


def lock_info_from_url(url):
    file_scheme = "file://"
    prefix_len = len(file_scheme)
    if not url.startswith(file_scheme):
        return url, None
    full_path = Path(url[prefix_len:]).absolute()
    return lock_info_from_store_path(full_path)


def lock_entry_from_report_entry(install):
    """
    Convert an entry of report['install'] to an object we want to store
    in our lock file, but don't add dependencies yet.
    """
    name = canonicalize_name(install["metadata"]["name"])
    download_info = install["download_info"]
    url, sha256 = lock_info_from_url(download_info["url"])
    if not sha256:
        hash = (
            download_info.get("archive_info", {})
            .get("hash", "")
            .split("=", 1)  # noqa: 501
        )
        sha256 = hash[1] if hash[0] == "sha256" else None
    return name, dict(
        url=url,
        version=install["metadata"]["version"],
        sha256=sha256,
        dependencies=set(),
    )


def evaluate_extras(req, extras, env):
    """
    Given a python requirement string, a dictionary representing a python
    platform environment as in report['environment'], and a set of extras,
    we want to check if this package is required on this platform with the
    requested extras.
    """
    if not extras:
        return req.marker.evaluate({**env, "extra": ""})
    else:
        return any({req.marker.evaluate({**env, "extra": e}) for e in extras})


def evaluate_requirements(env, reqs, packages, root_name, extras, seen):
    """
    Recursively walk the dependency tree and check if requirements
    are needed for our current platform with our requested set of extras.
    If so, add them to our lock files dependencies field and delete
    requirements to save space in the file.
    A circuit breaker is included to avoid infinite recursion in nix.
    """
    if root_name in seen:
        print(
            f"fatal: cycle detected: {root_name} ({' '.join(seen)})",
            file=sys.stderr,  # noqa: E501
        )
        sys.exit(1)
    # we copy "seen", because we want to track cycles per
    # tree-branch and the original would be visible for all branches.
    seen = seen.copy()
    seen.append(root_name)

    for req in reqs[root_name]:
        if (not req.marker) or evaluate_extras(req, extras, env):
            req_name = canonicalize_name(req.name)
            packages[root_name]["dependencies"].add(req_name)
            evaluate_requirements(
                env, reqs, packages, req_name, req.extras, seen
            )  # noqa: 501


def lock_file_from_report(report):
    """
    Pre-process pips report.json for easier consumation by nix.
    We extract name, version, url and hash of the source distribution or
    wheel. We also preprocess requirements and their environment markers to
    the effective, platform-specific dependencies of each package. This makes
    heavy use of `packaging` which is hard to impossible to re-implement
    correctly in nix.

    We output a dictionary mapping normalized package names to a dict
    of version, url, sha256 and a list of normalized names of the packages
    effective dependencies on this platform and with the extras requested.

    This function can be further improved by also locking dependencies for
    non-selected extras, provided by our toplevel packages aka "roots".
    """
    packages = dict()
    # environment to evaluate pythons requirement markers in, contains
    # things such as your operating system, platform and python interpreter.
    env = report["environment"]
    # trace packages directly requested from pip to know where to start
    # walking the dependency tree.
    roots = dict()
    # packages in the report are a list, so we cache their requirement
    # strings in a list for faster lookups while we walk the tree below.
    requirements = dict()

    # iterate over all packages pip installed to find roots
    # of the tree and gather basic information, such as urls
    for install in report["install"]:
        name, package = lock_entry_from_report_entry(install)
        packages[name] = package
        requirements[name] = map(
            Requirement, install["metadata"].get("requires_dist", [])
        )
        if install.get("requested", False):
            roots[name] = install.get("requested_extras", set())

    # recursively iterate over the dependency tree from top to bottom
    # to evaluate optional requirements (extras) correctly
    for root_name, extras in roots.items():
        evaluate_requirements(
            env, requirements, packages, root_name, extras, list()
        )  # noqa: 501

    # iterate over the packages a third and final time to ensure that
    # dependencies are a stable sorted list, no matter in which order the
    # tree has been walked through.
    packages = {
        name: {**pkg, "dependencies": sorted(list(pkg["dependencies"]))}
        for name, pkg in packages.items()
    }
    return packages


def get_max_date(snapshot_date):
    try:
        return int(snapshot_date)
    except ValueError:
        return dateutil.parser.parse(snapshot_date)


def prepare_venv(venv_path, pip_version):
    subprocess.run([sys.executable, "-m", "venv", venv_path], check=True)
    subprocess.run(
        [
            f"{venv_path}/bin/pip",
            "install",
            "--upgrade",
            f"pip=={pip_version}",
        ],
        check=True,
        stdout=sys.stderr,
        stderr=sys.stderr,
    )
    return venv_path


if __name__ == "__main__":
    with open(sys.argv[1], "r") as f:
        args = json.load(f)

    with tempfile.TemporaryDirectory() as home:
        home = Path(home)

        print(
            f"selected maximum release date for python packages: {get_max_date(args['pypiSnapshotDate'])}",  # noqa: E501
            file=sys.stderr,
        )

        proxy = Proxy(
            executable=args["mitmProxy"],
            args=[
                "--ignore-hosts",
                ".*files.pythonhosted.org.*",
                "--script",
                args["filterPypiResponsesScript"],
            ],
            env={"pypiSnapshotDate": args["pypiSnapshotDate"], "HOME": home},
        )

        venv_path = prepare_venv(
            (home / ".venv").absolute(), args["pipVersion"]
        )  # noqa: 501

        flags = args["pipFlags"] + [
            "--proxy",
            f"https://localhost:{proxy.port}",
            "--progress-bar",
            "off",
            "--cert",
            proxy.cafile,
            "--report",
            str(home / "report.json"),
        ]
        for req in args["requirementsList"]:
            if req:
                flags.append(req)
        for req in args["requirementsFiles"]:
            if req:
                flags += ["-r", req]

        subprocess.run(
            [
                f"{venv_path}/bin/pip",
                "install",
                "--dry-run",
                "--ignore-installed",
                # "--use-feature=fast-deps",
                *flags,
            ],
            check=True,
            stdout=sys.stderr,
            stderr=sys.stderr,
        )
        proxy.kill()

        with open(home / "report.json", "r") as f:
            report = json.load(f)
        with open(os.getenv("out"), "w") as f:
            lock = lock_file_from_report(report)
            json.dump(lock, f, indent=2, sort_keys=True)
